# 缓存和超标量优化实验报告

## 实验目的

本实验旨在探索现代计算机体系结构中缓存和超标量对程序性能的影响，通过两个关键任务实现不同算法策略并分析其性能差异：
1. 矩阵向量乘法优化：逐列访问与缓存优化算法对比
2. 向量求和优化：链式累加与超标量优化算法对比，以及使用宏/模板技术彻底消除循环

## 实验环境

- 操作系统：Windows 10 (WSL Ubuntu)
- 编译器：GCC
- 编译选项：-O0, -O1, -O2, -O3

## 任务一：矩阵向量乘法优化

### 算法设计

本任务实现了两种矩阵向量乘法算法：

1. **平凡算法**：逐列访问矩阵元素
```cpp
for(int i = 0; i < n; i++) {
    sum[i] = 0.0;
    for(int j = 0; j < n; j++) {
        sum[i] += matrix[j][i] * vec[j];
    }
}
```

2. **缓存优化算法**：逐行访问矩阵元素
```cpp
for(int i = 0; i < n; i++) {
    sum[i] = 0.0;
}
for(int j = 0; j < n; j++) {
    for(int i = 0; i < n; i++) {
        sum[i] += matrix[j][i] * vec[j];
    }
}
```

### 性能分析

基于实验结果，我们可以得出以下观察：

1. **缓存命中率**：
   - 平凡算法：由于逐列访问矩阵，在行优先存储方式下，存在较差的空间局部性
   - 缓存优化算法：通过逐行访问，充分利用了行优先存储的空间局部性，提高了缓存命中率

2. **加速比**：
   - 在n=1000时，缓存优化算法比平凡算法大约快3-5倍
   - 随着问题规模增大，加速比呈现增长趋势，这表明缓存优化在大规模数据上更有效

3. **优化级别影响**：
   - 在-O0优化级别下，两种算法的差距最为明显
   - 随着编译优化级别的提高，编译器可能会自动优化访存模式，缩小两种算法的性能差距

## 任务二：向量求和优化

### 算法设计

本任务实现了多种向量求和算法：

1. **平凡算法**：链式累加
```cpp
double sum = 0.0;
for (int i = 0; i < n; i++) {
    sum += arr[i];
}
```

2. **两路链式累加**：超标量优化
```cpp
double sum1 = 0.0, sum2 = 0.0;
for (int i = 0; i < n; i += 2) {
    if (i + 1 < n) {
        sum1 += arr[i];
        sum2 += arr[i + 1];
    } else {
        sum1 += arr[i];
    }
}
return sum1 + sum2;
```

3. **四路链式累加**：更多的指令级并行
```cpp
double sum1 = 0.0, sum2 = 0.0, sum3 = 0.0, sum4 = 0.0;
for (int i = 0; i < n; i += 4) {
    if (i + 3 < n) {
        sum1 += arr[i];
        sum2 += arr[i + 1];
        sum3 += arr[i + 2];
        sum4 += arr[i + 3];
    } else {
        // 处理剩余元素
    }
}
return sum1 + sum2 + sum3 + sum4;
```

4. **循环展开**：
```cpp
for (; i + 7 < n; i += 8) {
    sum += arr[i];
    sum += arr[i + 1];
    // ... 展开8次
}
```

5. **宏/模板实现的无循环算法**：

   a. **宏递归展开**：通过递归宏定义实现不同层次的展开
   ```cpp
   #define SUM_2(arr, start) ((arr)[start] + (arr)[start+1])
   #define SUM_4(arr, start) (SUM_2(arr, start) + SUM_2(arr, start+2))
   #define SUM_8(arr, start) (SUM_4(arr, start) + SUM_4(arr, start+4))
   // ... 一直展开到SUM_256
   ```
   
   b. **模板元编程无循环求和**：在编译时展开循环
   ```cpp
   template<size_t N>
   struct FixedSizeSum {
       static double sum(const vector<double>& arr, size_t start = 0) {
           return arr[start] + FixedSizeSum<N-1>::sum(arr, start+1);
       }
   };
   ```
   
   c. **混合宏模板求和**：宏和循环的结合
   ```cpp
   double sum = 0.0;
   while (i + 256 <= n) {
       sum += SUM_256(arr, i);
       i += 256;
   }
   // 处理剩余元素...
   ```
   
   d. **纯模板元编程无循环求和**：真正在编译期完全展开的实现
   ```cpp
   template<size_t N>
   double pure_template_sum(const vector<double>& arr) {
       if (arr.size() < N) {
           throw std::out_of_range("Array size too small");
       }
       return VectorSumHelper<N>::sum(arr);
   }
   ```
   
   e. **多路纯模板元编程**：结合纯模板和指令级并行
   ```cpp
   template<size_t N>
   struct TwoWayPureSum {
       static double sum(const vector<double>& arr, size_t start = 0) {
           constexpr size_t half = N / 2;
           return FixedSizeSum<half>::sum(arr, start) + 
                  FixedSizeSum<half>::sum(arr, start + half);
       }
   };
   ```

### 性能分析

基于实验结果，我们可以得出以下观察：

1. **超标量优化效果**：
   - 两路/四路链式累加显著优于平凡算法，在规模为100000的向量上能获得1.5x-3x的加速
   - 四路累加在大多数情况下优于两路累加，表明增加独立计算路径有利于指令级并行

2. **循环展开效果**：
   - 循环展开在-O0优化下比平凡算法有所改进
   - 在高优化级别(-O2, -O3)下，编译器可能已经自动进行循环展开，使显式展开效果不明显

3. **无循环技术的性能表现**：
   - 宏模板混合求和在-O0优化级别下通常优于普通循环实现，展示了预处理和编译时优化的效果
   - 在-O3优化级别下，宏模板混合方法表现尤为突出，对于100万元素的数组能达到2.7倍加速
   - 两路和四路宏模板方法同时利用了无循环和指令级并行，在大规模数据集上表现良好

4. **纯模板元编程效果**：
   - 在-O0优化级别下，纯模板元编程方法的性能不如循环方法，可能是由于模板展开导致的代码膨胀
   - 在-O3优化级别下，纯模板四路并行方法表现较好，比单路纯模板快近40%
   - 纯模板方法的主要限制是只能处理编译时固定大小的数组，这限制了其在实际应用中的通用性
   - 纯模板方法在-O3下的加速比不明显，说明编译器优化可能已经弥补了手动循环展开的优势

5. **无循环技术的代码复杂度**：
   - 无循环技术使代码更为复杂，但生成的机器码可能更为高效
   - 模板元编程技术加重了编译期负担，但减轻了运行时开销
   - 宏展开方法可能导致代码体积增大，但减少了分支预测失败

6. **不同规模数据的表现**：
   - 在小规模数据上(1000元素)，无循环技术的优势不明显，甚至可能因代码膨胀而性能下降
   - 在中等规模数据上(10000-100000元素)，混合宏模板方法结合多路并行显示出明显优势
   - 在大规模数据上(1000000元素)，缓存因素开始影响性能，宏模板技术的性能优势相对更为显著

## 编译优化对比

通过比较不同编译优化级别(-O0, -O3)下的性能，我们发现：

1. **-O0 (无优化)**：
   - 算法间的性能差异最为明显
   - 宏模板混合方法在此优化级别下效果明显，可提供约2倍加速
   - 纯模板元编程方法在此级别下性能较差，可能是由于未经优化的模板展开代码过于冗长

2. **-O3 (最高优化)**：
   - 编译器会进行积极的自动向量化、循环展开和内联
   - 平凡算法被自动优化，与手动优化算法的性能差距缩小
   - 宏模板混合方法仍保持良好性能，对于大型数组可提供约3倍加速
   - 纯模板方法加速比有所提升，但仍然受限于固定大小的约束

## 实验结论

1. **缓存优化**：
   - 逐行访问矩阵在行优先存储中能显著提高缓存命中率
   - 随着问题规模增大，缓存优化的效果更加明显，这与现代处理器的多级缓存结构相符

2. **超标量优化**：
   - 多路并行累加能有效减少指令依赖，提高处理器的指令级并行能力
   - 适度的循环展开能减少循环控制开销，提高指令执行效率

3. **无循环技术**：
   - 宏展开技术在预处理时消除循环结构，减少分支预测失败和循环控制开销
   - 混合宏模板技术结合了宏的预处理展开和运行时的灵活处理，在大数组上表现最佳
   - 纯模板元编程完全消除循环的方法理论上最优，但实际性能受限于编译时固定大小的约束
   - 对于较小的固定大小数组，纯模板多路并行方法可以提供明显优势

4. **编译器优化的关系**：
   - 高级编译优化能自动应用许多手动优化策略，对于简单循环往往能产生接近手动优化的效果
   - 宏模板混合方法在各优化级别下都能保持良好性能，提供了很好的通用性
   - 纯模板方法在高优化级别下表现更好，但仍需权衡其灵活性和代码复杂度的增加

## 未来工作

1. 进一步探索更复杂的缓存优化策略，如阻塞和数据预取
2. 结合SIMD指令(如AVX2)与无循环技术进行显式向量化
3. 测试更大规模的问题，观察与系统内存层次结构的交互
4. 使用性能分析工具(如perf)深入分析缓存命中/缺失率和分支预测准确率
5. 研究在模板元编程中如何更优雅地处理变长数组，以兼顾性能和灵活性
6. 将无循环和多路并行技术应用于更复杂的算法结构，如矩阵乘法和图算法 